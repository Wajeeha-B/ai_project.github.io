{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Execution for house price estimation"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Import relevant files and libraries\n",
            "import DataProcessor\n",
            "import sys\n",
            "import LRegression\n",
            "import NLRegression\n",
            "import performance_metrics\n",
            "import Kmeans\n",
            "import UserInterface\n",
            "import numpy as np\n",
            "import pandas as pd"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Define the parameters\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Allocate 80% of data to training\n",
            "train_size = 0.7\n",
            "\n",
            "# Identify features to be used\n",
            "columnsToKeep = ['Price','Type','Bedroom','Bathroom','Car','Landsize', 'BuildingArea', 'Latitude','Longitude']\n",
            "\n",
            "# Path to dataset.\n",
            "filepath = '../dataset/Melbourne_housing_FULL.csv'\n",
            "\n",
            "# Identify prediction (ground truth)\n",
            "prediction_column = 'Price'"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Process raw data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Create a DataProcessor object and load the data\n",
            "dp_obj = DataProcessor.DataProcessor()\n",
            "dp_obj.LoadData(filepath)\n",
            "\n",
            "# Remove incomplete points, remove unused features and shuffle the data\n",
            "dp_obj.keepSelectedColumns(columnsToKeep)\n",
            "dp_obj.filterMelbourneData()\n",
            "\n",
            "dp_obj.remove_outliers(columnsToKeep, plot=False)\n",
            "\n",
            "# dp_obj.encodeCategoricalData(['Type'])\n",
            "dp_obj.shuffleData()\n",
            "dp_obj.reduceDataSize(1000) # remove this to train on the full dataset\n",
            "\n",
            "\n",
            "columnsToCorrelate = ['Price','Bedroom','Bathroom','Car','Landsize', 'BuildingArea', 'Latitude','Longitude']\n",
            "dp_obj.calculateCorelation(columnsToCorrelate)\n",
            "\n",
            "# Split the data into training and testing\n",
            "train_X, train_Y, test_X, test_Y = dp_obj.splitData(train_size, prediction_column)\n",
            "\n",
            "# print(train_X.head())\n",
            "\n",
            "# Remove dwelling type and additional landsize / building area data for some processing\n",
            "clean_columns = ['Type', 'Landsize']\n",
            "train_X_clean = train_X.drop(columns=clean_columns,axis=1)\n",
            "test_X_clean = test_X.drop(columns=clean_columns,axis=1)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "K-Means Clustering"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Ashton\n",
            "k = 3\n",
            "prefs = ['Bedroom','Bathroom','Car','Landsize','Latitude','Longitude']\n",
            "\n",
            "all_points = []\n",
            "all_centroids = []\n",
            "\n",
            "for pref in prefs:\n",
            "    kmeansTrain = Kmeans.Kmeans(train_X, train_Y, k, pref)\n",
            "\n",
            "    train_X, points, centroids = kmeansTrain.cluster()\n",
            "\n",
            "    all_points.append(points)\n",
            "    all_centroids.append(centroids)\n",
            "    \n",
            "    # Plot the data\n",
            "    kmeansTrain.plotKmean(train_X, points, centroids, pref)\n",
            "\n",
            "for pref in prefs:\n",
            "    kmeansTest = Kmeans.Kmeans(test_X, test_Y, k, pref)\n",
            "\n",
            "    test_X, points, centroids = kmeansTest.cluster()\n",
            "\n",
            "    all_points.append(points)\n",
            "    all_centroids.append(centroids)\n",
            "\n",
            "    # Plot the data\n",
            "    # kmeansTest.plotKmean(test_X, points, centroids, pref)\n",
            "\n",
            "# kmeans = Kmeans.Kmeans(train_X, train_Y, k, prefs)\n",
            "\n",
            "# train_X, points, centroids = kmeans.cluster()\n",
            "\n",
            "# all_points.append(points)\n",
            "# all_centroids.append(centroids)\n",
            "\n",
            "# kmeans.plotKmean(train_X, points, centroids, prefs)\n",
            "\n",
            "print('train_X columns')\n",
            "print(train_X.columns)\n",
            "\n",
            "print('test_X columns')\n",
            "print(test_X.columns)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Linear Regression"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Train\n",
            "lr = LRegression.LRegression()\n",
            "values = ['Bedroom','Bathroom','Car','Landsize','BuildingArea','Latitude','Longitude']\n",
            "assignments = ['AssignmentBedroom','AssignmentBathroom','AssignmentCar','AssignmentLandsize','AssignmentBuildingArea','AssignmentLatitude','AssignmentLongitude']\n",
            "\n",
            "# Initialise weights\n",
            "w = []\n",
            "\n",
            "# Initialise MSE\n",
            "train_mse = []\n",
            "\n",
            "# Calculate weights for houses\n",
            "for i in range(k):\n",
            "    weight = lr.LinReg(train_X,train_Y,values,assignments,i)\n",
            "    w.append(weight)\n",
            "w = np.array(w)\n",
            "w = w.reshape(w.shape[0],w.shape[1],-1)\n",
            "\n",
            "# Calculate MSE for houses\n",
            "for i in range(k):\n",
            "    train_mse.append(lr.MSE(train_X[values],w[i,:],train_Y))\n",
            "print(\"Training error (houses) = \", train_mse)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Test\n",
            "\n",
            "# Initialise MSE\n",
            "test_mse = []\n",
            "\n",
            "# Calculate MSE for houses\n",
            "for i in range(k):\n",
            "    test_mse.append(lr.MSE(test_X[values],w[i,:],test_Y))\n",
            "print(\"Testing error (houses) = \", test_mse)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Non-Linear Regression (Gaussian Processing)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# # creating interaction features based on the assigned cluster\n",
            "\n",
            "# assignments = ['AssignmentBedroom','AssignmentBathroom','AssignmentCar','AssignmentLandsize','AssignmentLatitude','AssignmentLongitude']\n",
            "# features = ['Bedroom','Bathroom','Car','Landsize', 'Latitude','Longitude']\n",
            "\n",
            "# # get the average assignment value for each house (row)\n",
            "# train_X['AverageAssignment'] = train_X[assignments].mean(axis=1)\n",
            "# test_X['AverageAssignment'] = test_X[assignments].mean(axis=1)\n",
            "\n",
            "\n",
            "# train_X['Bedroom'] = train_X['Bedroom'] * train_X['AssignmentBedroom']\n",
            "# train_X['Bathroom'] = train_X['Bathroom'] * train_X['AssignmentBathroom']\n",
            "# train_X['Car'] = train_X['Car'] * train_X['AssignmentCar']\n",
            "# train_X['Landsize'] = train_X['Landsize'] * train_X['AssignmentLandsize']\n",
            "# train_X['BuildingArea'] = train_X['BuildingArea'] * train_X['AssignmentLandsize']\n",
            "# train_X['Latitude'] = train_X['Latitude'] * train_X['AssignmentLatitude']\n",
            "# train_X['Longitude'] = train_X['Longitude'] * train_X['AssignmentLongitude']\n",
            "\n",
            "# test_X['Bedroom'] = test_X['Bedroom'] * test_X['AssignmentBedroom']\n",
            "# test_X['Bathroom'] = test_X['Bathroom'] * test_X['AssignmentBathroom']\n",
            "# test_X['Car'] = test_X['Car'] * test_X['AssignmentCar']\n",
            "# test_X['Landsize'] = test_X['Landsize'] * test_X['AssignmentLandsize']\n",
            "# test_X['BuildingArea'] = test_X['BuildingArea'] * test_X['AssignmentLandsize']\n",
            "# test_X['Latitude'] = test_X['Latitude'] * test_X['AssignmentLatitude']\n",
            "# test_X['Longitude'] = test_X['Longitude'] * test_X['AssignmentLongitude']\n",
            "\n",
            "\n",
            "\n",
            "# multiple everything some scale. This is for testing purposes\n",
            "# scale = 2\n",
            "\n",
            "# train_X['Bedroom'] = train_X['Bedroom'] * scale\n",
            "# train_X['Bathroom'] = train_X['Bathroom'] * scale\n",
            "# train_X['Car'] = train_X['Car'] * scale\n",
            "# train_X['Landsize'] = train_X['Landsize'] * scale\n",
            "# train_X['BuildingArea'] = train_X['BuildingArea'] * scale\n",
            "# train_X['Latitude'] = train_X['Latitude'] * scale\n",
            "# train_X['Longitude'] = train_X['Longitude'] * scale\n",
            "\n",
            "# test_X['Bedroom'] = test_X['Bedroom'] * scale\n",
            "# test_X['Bathroom'] = test_X['Bathroom'] * scale\n",
            "# test_X['Car'] = test_X['Car'] * scale\n",
            "# test_X['Landsize'] = test_X['Landsize'] * scale\n",
            "# test_X['BuildingArea'] = test_X['BuildingArea'] * scale\n",
            "# test_X['Latitude'] = test_X['Latitude'] * scale\n",
            "# test_X['Longitude'] = test_X['Longitude'] * scale\n",
            "\n",
            "# print(train_X.head())\n",
            "# print(test_X.head())\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Train\n",
            "\n",
            "# must be ordered by correlation to price (highest to lowest)\n",
            "featuresToTrain = ['Latitude', 'BuildingArea', 'Landsize', 'Longitude'] # ['Size','Latitude', 'AssignmentLatitude' ,'Longitude', 'AssignmentLongitude']\n",
            "\n",
            "# ask to train or load a model\n",
            "query = input(\"Do you want to train a new model? (y/n): \")\n",
            "if query == 'y':\n",
            "    # Ask user for features to train on\n",
            "    nlr = NLRegression.NLRegression(train_X, train_Y, test_X, test_Y, featuresToTrain)\n",
            "    nlr.train()\n",
            "    # ask to save\n",
            "    query = input(\"Do you want to save the model? (y/n): \")\n",
            "    if query == 'y':\n",
            "        _, _, r_2 = nlr.evaluate()\n",
            "        filepath_ = '../saved_models/nlr_model_R_2_' + str(r_2)\n",
            "        nlr.saveModel(filepath_)\n",
            "else:\n",
            "    nlr = NLRegression.NLRegression(train_X, train_Y, test_X, test_Y, featuresToTrain)\n",
            "    filename_ = input(\"Enter the filename of the model to load: \")\n",
            "    filepath_ = '../saved_models/' + filename_\n",
            "    nlr.loadModel(filepath_)\n",
            "\n",
            "# plotting predictions vs expected\n",
            "nlr.plot()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# splits training data into folds and performs cross validation. If this value is greater\n",
            "# than the previous R^2 score, the model is probably overfitting\n",
            "nlr.cross_validate()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Examine an individual test sample\n",
            "sample_number = 30\n",
            "\n",
            "sample = test_X[featuresToTrain].iloc[sample_number]\n",
            "print(\"sample: \", sample.values)\n",
            "\n",
            "# Predict using the model with the scaled data\n",
            "pred, bounds = nlr.predictActual(sample)\n",
            "print(\"prediction: \", pred[0])\n",
            "# print(\"bounds:     \", bounds[0], bounds[1])\n",
            "print(\"actual:     \", test_Y.iloc[sample_number])"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Evaluation Metrics"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from performance_metrics import ElbowMethod\n",
            "from DataProcessor import DataProcessor\n",
            "import pandas as pd\n",
            "from sklearn.impute import SimpleImputer\n",
            "\n",
            "# Identify features to be used (excluding 'Type')\n",
            "columnsToKeep = ['Price', 'Bedroom', 'Bathroom', 'Car', 'Landsize', 'BuildingArea', 'Latitude', 'Longitude']\n",
            "\n",
            "# Path to dataset\n",
            "filepath = '../dataset/Melbourne_housing_FULL.csv'\n",
            "\n",
            "# Step 1: Load and preprocess the data\n",
            "data_processor = DataProcessor()\n",
            "data = data_processor.LoadData(filepath)\n",
            "\n",
            "# Drop columns that are not relevant or cannot be converted to numeric\n",
            "data = data_processor.keepSelectedColumns(columnsToKeep)\n",
            "\n",
            "# Impute missing values with the mean of each column\n",
            "imputer = SimpleImputer(strategy='mean')\n",
            "data = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
            "\n",
            "# Step 2: Use the ElbowMethod class with the preprocessed data\n",
            "elbow_method = ElbowMethod(data)  # Initialize ElbowMethod\n",
            "elbow_method.evaluate(max_clusters=10)\n",
            "elbow_method.plot()\n",
            "optimal_clusters = elbow_method.optimal_number_of_clusters()\n",
            "print(\"Optimal number of clusters:\", optimal_clusters)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Data Preprocessing\n",
            "from sklearn.preprocessing import StandardScaler\n",
            "from Kmeans import Kmeans\n",
            "from performance_metrics import ElbowMethod\n",
            "\n",
            "# Load and preprocess the data\n",
            "data_processor = DataProcessor()\n",
            "data = data_processor.LoadData(filepath)\n",
            "data = data_processor.keepSelectedColumns(columnsToKeep)\n",
            "imputer = SimpleImputer(strategy='mean')\n",
            "data = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
            "scaler = StandardScaler()\n",
            "data_scaled = scaler.fit_transform(data)\n",
            "\n",
            "# Elbow Method for Optimal K\n",
            "elbow_method = ElbowMethod(data_scaled)\n",
            "elbow_method.evaluate(max_clusters=10)\n",
            "elbow_method.plot()\n",
            "optimal_clusters = elbow_method.optimal_number_of_clusters()\n",
            "print(\"Optimal number of clusters:\", optimal_clusters)\n",
            "print(train_X.columns)\n",
            "print(train_X)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from sklearn.metrics import silhouette_score\n",
            "\n",
            "# Assuming kmeans.cluster() returns x_new, points, centroids\n",
            "kmeans_instance = Kmeans(train_X, train_Y, optimal_clusters, pref)\n",
            "x_new, points, centroids = kmeans_instance.cluster()\n",
            "assignment = x_new['Assignment' + pref].values  # Extract the cluster assignments\n",
            "\n",
            "silhouette_avg = silhouette_score(points, assignment)\n",
            "print(\"Silhouette Score:\", silhouette_avg)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from sklearn.metrics import silhouette_score\n",
            "\n",
            "# Assuming kmeans.cluster() returns x_new, points, centroids\n",
            "kmeans_instance = Kmeans(train_X, train_Y, optimal_clusters, pref)\n",
            "x_new, points, centroids = kmeans_instance.cluster()\n",
            "assignment = x_new['Assignment' + pref].values  # Extract the cluster assignments\n",
            "\n",
            "silhouette_avg = silhouette_score(points, assignment)\n",
            "print(\"Silhouette Score:\", silhouette_avg)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "User input for preference"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Calculate mean values if no user preference is provided\n",
            "meanLand = dp_obj.getAverage('Landsize')\n",
            "meanBuilding = dp_obj.getAverage('BuildingArea')\n",
            "\n",
            "# Input user preferences\n",
            "user_pref = UserInterface.UserInterface()\n",
            "bedrooms, bathrooms, car, landsize, buildingarea, latitude, longitude = user_pref.Inputs(meanLand, meanBuilding)\n",
            "print(\"Bedrooms = \",bedrooms,\" Bathrooms = \",bathrooms,\" Car parks = \",car,\" Land size = \",landsize,\" Building area = \",buildingarea,\" Latitude = \",latitude,\" Longitude = \",longitude)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Final prediction"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Return predicted value from Linear Regression\n",
            "\n",
            "# Assign feature inputs\n",
            "targets = [bedrooms,bathrooms,car,landsize,buildingarea,latitude,longitude]\n",
            "\n",
            "# Make prediction for each level\n",
            "pred = lr.predict(targets,w)\n",
            "\n",
            "# Return minimum value\n",
            "print(\"Minimum value = $\",np.min(pred))\n",
            "\n",
            "# Return maximum value\n",
            "print(\"Maximum value = $\",np.max(pred))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# featuresToTrain = ['Latitude', 'BuildingArea', 'Landsize', 'Longitude'] # ['Size','Latitude', 'AssignmentLatitude' ,'Longitude', 'AssignmentLongitude']\n",
            "\n",
            "\n",
            "sample = pd.Series([latitude, buildingarea, landsize, longitude], index=featuresToTrain)\n",
            "pred, bounds = nlr.predictActual(sample)\n",
            "print(\"prediction: \", pred[0])\n",
            "# print(\"bounds:     \", bounds[0], bounds[1])"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "groupEnv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.8.19"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
