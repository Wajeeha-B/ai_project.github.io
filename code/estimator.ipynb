{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Execution for house price estimation"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Import relevant files and libraries\n",
            "import DataProcessor\n",
            "import sys\n",
            "import LRegression\n",
            "import NLRegression\n",
            "import performance_metrics\n",
            "import Kmeans\n",
            "import UserInterface\n",
            "import numpy as np\n",
            "import pandas as pd"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Define the parameters\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Allocate 80% of data to training\n",
            "train_size = 0.8\n",
            "\n",
            "# Identify features to be used\n",
            "columnsToKeep = ['Price','Type','Bedroom','Bathroom','Car','Landsize','BuildingArea','Latitude','Longitude']\n",
            "#columnsToKeep = ['Price', 'Bedroom', 'Bathroom']\n",
            "#columnsToKeep = ['Price', 'Type', 'Landsize', 'BuildingArea']\n",
            "\n",
            "# Path to dataset.\n",
            "filepath = '../dataset/Melbourne_housing_FULL.csv'\n",
            "\n",
            "# Identify prediction (ground truth)\n",
            "prediction_column = 'Price'"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Process raw data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Create a DataProcessor object and load the data\n",
            "dp_obj = DataProcessor.DataProcessor()\n",
            "dp_obj.LoadData(filepath)\n",
            "\n",
            "# Remove incomplete points, remove unused features and shuffle the data\n",
            "dp_obj.keepSelectedColumns(columnsToKeep)\n",
            "dp_obj.filterMelbourneData()\n",
            "\n",
            "dp_obj.remove_outliers(columnsToKeep, plot=False)\n",
            "\n",
            "# dp_obj.encodeCategoricalData(['Type'])\n",
            "dp_obj.shuffleData()\n",
            "dp_obj.reduceDataSize(1500) # remove this to train on the full dataset\n",
            "\n",
            "\n",
            "columnsToCorrelate = ['Price','Bedroom','Bathroom','Car','Landsize','BuildingArea','Latitude','Longitude']\n",
            "dp_obj.calculateCorelation(columnsToCorrelate)\n",
            "\n",
            "# Split the data into training and testing\n",
            "train_X, train_Y, test_X, test_Y = dp_obj.splitData(train_size, prediction_column)\n",
            "\n",
            "# print(train_X.head())\n",
            "\n",
            "# Remove dwelling type and additional landsize / building area data for some processing\n",
            "clean_columns = ['Type', 'Landsize','BuildingArea']\n",
            "train_X_clean = train_X.drop(columns=clean_columns,axis=1)\n",
            "test_X_clean = test_X.drop(columns=clean_columns,axis=1)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "K-Means Clustering"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Ashton\n",
            "k = 3\n",
            "# prefs = ['Type','Bedroom','Bathroom','Car','Landsize','BuildingArea','Latitude','Longitude']\n",
            "prefs = ['Type','Bedroom','Bathroom','Car','Landsize','BuildingArea','Latitude','Longitude']\n",
            "\n",
            "all_points = []\n",
            "all_centroids = []\n",
            "\n",
            "for pref in prefs:\n",
            "    kmeansTrain = Kmeans.Kmeans(train_X, train_Y, k, pref)\n",
            "\n",
            "    train_X, points, centroids = kmeansTrain.cluster()\n",
            "\n",
            "    all_points.append(points)\n",
            "    all_centroids.append(centroids)\n",
            "    \n",
            "    # Plot the data\n",
            "    # kmeansTrain.plotKmean(train_X, points, centroids, pref)\n",
            "\n",
            "for pref in prefs:\n",
            "    kmeansTest = Kmeans.Kmeans(test_X, test_Y, k, pref)\n",
            "\n",
            "    test_X, points, centroids = kmeansTest.cluster()\n",
            "\n",
            "    all_points.append(points)\n",
            "    all_centroids.append(centroids)\n",
            "\n",
            "    # Plot the data\n",
            "    # kmeansTest.plotKmean(test_X, points, centroids, pref)\n",
            "\n",
            "# kmeans = Kmeans.Kmeans(train_X, train_Y, k, prefs)\n",
            "\n",
            "# train_X, points, centroids = kmeans.cluster()\n",
            "\n",
            "# all_points.append(points)\n",
            "# all_centroids.append(centroids)\n",
            "\n",
            "# kmeans.plotKmean(train_X, points, centroids, prefs)\n",
            "\n",
            "print('train_X columns')\n",
            "print(train_X.columns)\n",
            "\n",
            "print('test_X columns')\n",
            "print(test_X.columns)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Linear Regression"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Train\n",
            "lr = LRegression.LRegression()\n",
            "values = ['Bedroom','Bathroom','Car','Landsize','BuildingArea','Latitude','Longitude']\n",
            "values_h = ['Bedroom','Bathroom','Car','Landsize','Latitude','Longitude']\n",
            "values_u = ['Bedroom','Bathroom','Car','BuildingArea','Latitude','Longitude']\n",
            "assignments = ['AssignmentBedroom','AssignmentBathroom','AssignmentCar','AssignmentLandsize','AssignmentBuildingArea','AssignmentLatitude','AssignmentLongitude']\n",
            "\n",
            "# For houses only\n",
            "train_Xh = train_X[train_X['Type'] == 'h'].drop(['BuildingArea','AssignmentBuildingArea'],axis=1)\n",
            "# For units only\n",
            "train_Xu = train_X[train_X['Type'] == 'u'].drop(['Landsize','AssignmentLandsize'],axis=1)\n",
            "\n",
            "# Initialise weights\n",
            "wh = []\n",
            "wu = []\n",
            "\n",
            "# Initialise MSE\n",
            "train_mse_h = []\n",
            "train_mse_u = []\n",
            "\n",
            "# Calculate weights for houses\n",
            "for i in range(k):\n",
            "    weight = lr.LinReg(train_Xh,train_Y[train_X['Type'] == 'h'],values,assignments,i)\n",
            "    wh.append(weight)\n",
            "wh = np.array(wh)\n",
            "wh = wh.reshape(wh.shape[0],wh.shape[1],-1)\n",
            "\n",
            "# Calculate MSE for houses\n",
            "for i in range(k):\n",
            "    train_mse_h.append(lr.MSE(train_Xh[values_h],wh[i,:],train_Y[train_X['Type'] == 'h']))\n",
            "print(\"Training error (houses) = \", train_mse_h)\n",
            "\n",
            "# Calculate weights for units\n",
            "for i in range(k):\n",
            "    weight = lr.LinReg(train_Xu,train_Y[train_X['Type'] == 'u'],values,assignments,i)\n",
            "    wu.append(weight)\n",
            "wu = np.array(wu)\n",
            "wu = wu.reshape(wu.shape[0],wu.shape[1],-1)\n",
            "\n",
            "# Calculate MSE for units\n",
            "for i in range(k):\n",
            "    train_mse_u.append(lr.MSE(train_Xu[values_u],wu[i,:],train_Y[train_X['Type'] == 'u']))\n",
            "print(\"Training error (units) = \", train_mse_u)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Test\n",
            "\n",
            "# For houses only\n",
            "test_Xh = test_X[test_X['Type'] == 'h'].drop(['BuildingArea','AssignmentBuildingArea'],axis=1)\n",
            "# For units only\n",
            "test_Xu = test_X[test_X['Type'] == 'u'].drop(['Landsize','AssignmentLandsize'],axis=1)\n",
            "\n",
            "# Initialise MSE\n",
            "test_mse_h = []\n",
            "test_mse_u = []\n",
            "\n",
            "# Calculate MSE for houses\n",
            "for i in range(k):\n",
            "    test_mse_h.append(lr.MSE(test_Xh[values_h],wh[i,:],test_Y[test_X['Type'] == 'h']))\n",
            "print(\"Testing error (houses) = \", test_mse_h)\n",
            "\n",
            "# Calculate MSE for units\n",
            "for i in range(k):\n",
            "    test_mse_u.append(lr.MSE(test_Xu[values_u],wu[i,:],test_Y[test_X['Type'] == 'u']))\n",
            "print(\"Testing error (units) = \", test_mse_u)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Non-Linear Regression (Gaussian Processing)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Train\n",
            "\n",
            "# options: 'Type','Bedroom','Bathroom','Car','Size','Latitude','Longitude'\n",
            "\n",
            "# ['Type', 'Bedroom', 'Bathroom', 'Car', 'Landsize', 'BuildingArea',\n",
            "#        'Latitude', 'Longitude', 'Size', 'AssignmentType', 'AssignmentBedroom',\n",
            "#        'AssignmentBathroom', 'AssignmentCar', 'AssignmentLandsize',\n",
            "#        'AssignmentBuildingArea', 'AssignmentLatitude', 'AssignmentLongitude']\n",
            "\n",
            "# ['Size','Latitude','Longitude']\n",
            "\n",
            "featuresToTrain = ['Size','Latitude','Longitude', 'Bedroom', 'Bathroom'] # ['Size','Latitude', 'AssignmentLatitude' ,'Longitude', 'AssignmentLongitude']\n",
            "\n",
            "# ask to train or load a model\n",
            "query = input(\"Do you want to train a new model? (y/n): \")\n",
            "if query == 'y':\n",
            "    # Ask user for features to train on\n",
            "    nlr = NLRegression.NLRegression(train_X, train_Y, test_X, test_Y, featuresToTrain)\n",
            "    nlr.train()\n",
            "    # ask to save\n",
            "    query = input(\"Do you want to save the model? (y/n): \")\n",
            "    if query == 'y':\n",
            "        r_2, mae, mse = nlr.evaluate()\n",
            "        filepath_ = '../saved_models/nlr_model_R_2_' + str(r_2)\n",
            "        nlr.saveModel(filepath_)\n",
            "else:\n",
            "    nlr = NLRegression.NLRegression(train_X, train_Y, test_X, test_Y, featuresToTrain)\n",
            "    filename_ = input(\"Enter the filename of the model to load: \")\n",
            "    filepath_ = '../saved_models/' + filename_\n",
            "    nlr.loadModel(filepath_)\n",
            "\n",
            "# plotting predictions vs expected\n",
            "nlr.plot()\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# slow but more accurate test\n",
            "nlr.cross_validate()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Select a sample row and keep it as a Series\n",
            "sample_number = 200\n",
            "\n",
            "sample = test_X[featuresToTrain].iloc[sample_number]\n",
            "print(\"sample: \", sample.values)\n",
            "\n",
            "# Predict using the model with the scaled data\n",
            "pred, bounds = nlr.predictActual(sample)\n",
            "print(\"prediction: \", pred[0])\n",
            "# print(\"bounds:     \", bounds[0], bounds[1])\n",
            "print(\"actual:     \", test_Y.iloc[sample_number])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# generate fake sample to test. must be pandas series\n",
            "sample = pd.Series([100, 37.8, 144.9, 3, 2, 37.8, 144.9], index=featuresToTrain)\n",
            "pred, bounds = nlr.predictActual(sample)\n",
            "print(\"prediction: \", pred[0])\n",
            "# print(\"bounds:     \", bounds[0], bounds[1])\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Evaluation Metrics"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from performance_metrics import ElbowMethod\n",
            "from DataProcessor import DataProcessor\n",
            "import pandas as pd\n",
            "from sklearn.impute import SimpleImputer\n",
            "\n",
            "# Identify features to be used (excluding 'Type')\n",
            "columnsToKeep = ['Price', 'Bedroom', 'Bathroom', 'Car', 'Landsize', 'BuildingArea', 'Latitude', 'Longitude']\n",
            "\n",
            "# Path to dataset\n",
            "filepath = '../dataset/Melbourne_housing_FULL.csv'\n",
            "\n",
            "# Step 1: Load and preprocess the data\n",
            "data_processor = DataProcessor()\n",
            "data = data_processor.LoadData(filepath)\n",
            "\n",
            "# Drop columns that are not relevant or cannot be converted to numeric\n",
            "data = data_processor.keepSelectedColumns(columnsToKeep)\n",
            "\n",
            "# Impute missing values with the mean of each column\n",
            "imputer = SimpleImputer(strategy='mean')\n",
            "data = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
            "\n",
            "# Step 2: Use the ElbowMethod class with the preprocessed data\n",
            "elbow_method = ElbowMethod(data)  # Initialize ElbowMethod\n",
            "elbow_method.evaluate(max_clusters=10)\n",
            "elbow_method.plot()\n",
            "optimal_clusters = elbow_method.optimal_number_of_clusters()\n",
            "print(\"Optimal number of clusters:\", optimal_clusters)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from performance_metrics import calculate_silhouette_score\n",
            "# Assuming kmeans.cluster() returns x_new, points, centroids\n",
            "\n",
            "kmeans = Kmeans.Kmeans(train_X, train_Y, k, pref)\n",
            "\n",
            "x_new, points, centroids = kmeans.cluster()\n",
            "assignment = x_new['Assignment' + pref].values  # Extract the cluster assignments\n",
            "\n",
            "silhouette_avg = calculate_silhouette_score(points, assignment)\n",
            "print(\"Silhouette Score:\", silhouette_avg)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "User input for preference"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Calculate mean values if no user preference is provided\n",
            "meanLand = dp_obj.getAverage('Landsize')\n",
            "meanBuilding = dp_obj.getAverage('BuildingArea')\n",
            "\n",
            "# Input user preferences\n",
            "user_pref = UserInterface.UserInterface()\n",
            "type, bedrooms, bathrooms, car, size, latitude, longitude = user_pref.Inputs(meanLand, meanBuilding)\n",
            "print(type,bedrooms,bathrooms,car,size,latitude,longitude)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Final prediction"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Return predicted value from best performing model\n",
            "# @TODO: Update for building type\n",
            "# @TODO: Update for 'luxury' level (cluster number)\n",
            "# targets = [type,bedrooms,bathrooms,car,size,latitude,longitude]\n",
            "targets = [3,2,1,1000,100,-37.5903,145.2507]\n",
            "pred = lr.predict(targets,w[0,:])"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "groupEnv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.8.19"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
